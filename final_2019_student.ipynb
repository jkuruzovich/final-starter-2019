{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88E1SinoXESX"
   },
   "source": [
    "# Tech Fundamentals Final\n",
    "# enter your name here\n",
    "\n",
    "\"I pledge under the RPI honor code that I have completed this work on my own.\" \n",
    "\n",
    "At any time a monitor may ask you to scroll up to the top of this document to view this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bazbfl30iE3t"
   },
   "outputs": [],
   "source": [
    "#This just gets the data and preps the environment. \n",
    "data=\"https://www.dropbox.com/s/7kbq1hi31a7tnzt/data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6tm8adzbq58"
   },
   "outputs": [],
   "source": [
    "!wget $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NabIBvxWoICP"
   },
   "outputs": [],
   "source": [
    "!unzip -o data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "880XuoKaXJke"
   },
   "source": [
    "This is healthcare data generated from a syntetic data generator.  We want to see how good it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcsebVilY9Ue"
   },
   "outputs": [],
   "source": [
    "#Let's list the files\n",
    "!ls ./data/ma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vVUHm0Vi72N"
   },
   "outputs": [],
   "source": [
    "#Let's look at one of the dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "careplans_ma= pd.read_csv('./data/ma/careplans.csv')\n",
    "careplans_ny= pd.read_csv('./data/ny/careplans.csv')\n",
    "careplans_ma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-G1gjRxRXESa"
   },
   "source": [
    "# Exploratory Data Analysis \n",
    "\n",
    "The data directory includes a wide variety of data related to health care.  \n",
    "    \n",
    "(1. 5 points) Find the mean of the `COST` varaiable in the `encounters.csv` data for both NY and MA, assigning the values to `cost_ny` and `cost_ma`.   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6GWZeGvXESc"
   },
   "outputs": [],
   "source": [
    "# Answer 1\n",
    "\n",
    "#Load the data\n",
    "cost_ma=0 # Fix this to calculate the mean of the cost. (5 points)\n",
    "cost_ny=0 #Fix this to calculate the mean of the cost. (5 points)\n",
    "print( cost_ma, cost_ny)\n",
    "print (\"___\", \"    If you are seeing a face, probably aren't there yet. \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aMi_E27oICs"
   },
   "source": [
    "# Cost Regression Analysis\n",
    "\n",
    "### Dummy Creation and Splint to Train and Test for NY ONLY \n",
    "\n",
    "The goal of the code below is to predict the `COST` from `CODE` and `ENCOUNTERCLASS`.  \n",
    "\n",
    "\n",
    "(2. 5 points) First create dummies from `CODE` and `ENCOUNTERCLASS`.  Don't use any other variables.  split your data into an 70% train and 30% validation using a `random_state` of 111. For validation, set: \n",
    "\n",
    "```\n",
    "splittest1 = X_train.iloc[5,2]\n",
    "\n",
    "splittest2 = X_test.iloc[7,4]\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6EnzsJyoICu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Create Dummies. Also set  dummy_na = True\n",
    "\n",
    "#y ='COST'\n",
    "#X_train, X_test, y_train, y_test is the naming you should use\n",
    "#verify split\n",
    "\n",
    "#keep this code used for testing. \n",
    "splittest1 = X_train.shape\n",
    "splittest2 = X_test.iloc[7,4]\n",
    "print(splittest1, splittest2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nV6TiFTmoICx"
   },
   "source": [
    "### Predict Cost via Linear Regression \n",
    "\n",
    "(3. 10 points) Using linear regression analysis, use the `CODE` and `ENCOUNTERCLASS` as independent variables to predict `COST`. This is your naive model. Report R-Squared for both training `r2_train_cost` and validation `r2_test_cost`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKKqv5ZpoICy"
   },
   "outputs": [],
   "source": [
    "#3 Answer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "r2_train_cost = 0 # Make equal to the R2. \n",
    "r2_test_cost = 0# Make equal to the R2. \n",
    "\n",
    "#Keep this\n",
    "print('R2 for Train:', r2_train_cost)\n",
    "print('R2 for Test (cross validation)ï¼š', r2_test_cost )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAucAlQIoIC2"
   },
   "source": [
    "# Create Graph of Encounter class vs Cost\n",
    "\n",
    "(4. 10 points) Create a graph of encounter class vs cost. It should look like the graph below (created via seaborn). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5b0u7uyoIC3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vg4u1tjoXETL"
   },
   "outputs": [],
   "source": [
    "#4 Answer\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyOd-KhooIC-"
   },
   "source": [
    "When you are done your graph should look like this.  \n",
    "\n",
    "ENCOUNTERCLASS is on they axis and  and COST on X axis.\n",
    "\n",
    "![Imgur](https://i.imgur.com/asCDZSM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQ06eTNFXEXk"
   },
   "source": [
    "# High Cost Patients Classification \n",
    "\n",
    "A second Challenge is determinine the most expensive individuals.  This is set as all those groups that are more than 1 standard deviation above the mean, indicated as 'HIGHCOST' in the dataset.  \n",
    "\n",
    "(5. 5 points) \n",
    "Overall, count the total number of individuals who are high cost in NY (i.e., where encounters_ny['HIGHCOST'] is equal to 1.) Assign to the value `total_high_cost_ny`. \n",
    "\n",
    "Overall, count the total number of individuals who are high cost in MA (i.e., where encounters_ny['HIGHCOST'] is equal to 1.) Assign to the value `total_high_cost_ma`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPGRyrs4oIDA"
   },
   "outputs": [],
   "source": [
    "#5 Answer \n",
    "total_high_cost_ny=0  #set to the sum\n",
    "total_high_cost_ma=0 #set to the sum\n",
    "\n",
    "print(total_high_cost_ny, total_high_cost_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5mGGSz4oIDE"
   },
   "source": [
    "### Split the Train and test set for Classification with you DV set to HIGHCOST for NY Only. \n",
    "\n",
    "\n",
    "(6. 5 points) First split your data into an 70% train and 30% validation. Make sure that the results are *stratified* (equal classes in train and test) with `random_state = 111`.  \n",
    "\n",
    "Also set the following:\n",
    "\n",
    "```\n",
    "splittest3 = y_train.iloc[5]\n",
    "splittest4 = y_test.iloc[3]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RK4j7B0JoIDE"
   },
   "outputs": [],
   "source": [
    "#6 Answer \n",
    "#Set y equal to train encounters_ny['HIGHCOST'] \n",
    "y = encounters_ny['HIGHCOST']\n",
    "#X_train, X_test, y_train, y_test  is the naming you should use\n",
    "\n",
    "#This will be used for testing. Keep it. \n",
    "splittest3 = y_train.iloc[3]\n",
    "splittest4 = y_test.iloc[17]\n",
    "print (splittest3, splittest4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SZb1zDLoIDK"
   },
   "source": [
    "### Classification with Random Forrest\n",
    "(8. 5 points) Use a RandomForestClassifier to predict the 'HIGH_COST' with use the `CODE` and `ENCOUNTERCLASS` as independent variables.  \n",
    "\n",
    "Also set the following:\n",
    "\n",
    "```\n",
    "train_accuracy\n",
    "test_accuracy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIXHnQQsoIDL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_accuracy = 0#set to the accuracy\n",
    "test_accuracy = 0 #set to the accuracy\n",
    "#Keep this.\n",
    "print(\"Classifier Accuracy for Train: \", train_accuracy )\n",
    "print(\"Classifier Accuracy for Test: \", test_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zcSiCldTXEX2"
   },
   "source": [
    "### Submission\n",
    "For the final submission, please submit a link to this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnfviJwxXEX3"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install git+https://github.com/data-8/Gofer-Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tznNVOH_oIDR"
   },
   "outputs": [],
   "source": [
    "tests = \"https://github.com/jkuruzovich/final-starter-2019/raw/master/tests.zip\"\n",
    "ok=\"https://raw.githubusercontent.com/jkuruzovich/final-starter-2019/master/final.ok\"\n",
    "!wget  $ok && wget $tests && unzip -o tests.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-nE59nWgxVt"
   },
   "outputs": [],
   "source": [
    "#This loads the grading software.  If you later get a \"failed to import OK.py\" you need to rerun.\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('final.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1SKvmgEgzdZ"
   },
   "outputs": [],
   "source": [
    "#This runs the tests\n",
    "import os \n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "final_2019_student.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
